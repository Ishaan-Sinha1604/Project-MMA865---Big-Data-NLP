# Project-MMA865---Big-Data-NLP
A Natural Language Processing (NLP) project to predict whether an Amazon product review is "helpful" using text analytics, feature engineering, and ML modeling on a large-scale dataset. Completed as part of **MMA865 â€“ Big Data Analytics** at Queenâ€™s University.

---
## Project Overview

**Objective**:  
Predict whether a given Amazon review will be marked as helpful based on its textual content and metadata.

**Dataset**:  
- Source: [Amazon Product Reviews (1996â€“2018)](https://jmcauley.ucsd.edu/data/amazon/)
- Size: Over 3.14 million reviews

**Target Variable**:  
- `label = 1` (helpful), `label = 0` (not helpful)

---
## ğŸ§° Tech Stack

- **Platform**: Azure Databricks (All-Purpose Compute)
- **Language**: PySpark (Spark NLP)
- **Libraries**: Spark MLlib, Databricks Notebook, Pandas
- **Tools**: TF-IDF, Logistic Regression, Feature Indexing, Vector Assembler 

---

## ğŸ” Methodology

### ğŸ”„ Data Preprocessing
- Removed duplicates
- Converted data types (e.g., review time â†’ datetime)
- Extracted features: review length, days since review, verified status, reviewer ID, ASIN

### ğŸ§¼ Text Processing Pipeline
1. Document Assembler  
2. Tokenizer  
3. Normalizer  
4. Stop Words Removal  
5. Lemmatizer  
6. Finisher 

Additional(Not in Main Model): - 
1. SentenceDetector
2. Normalizer
3. PerceptronModel (Pos_Tagger)
4. Chunker
5. Word2VecModel
6. SentenceEmbeddings

### ğŸ— Feature Engineering
- One-hot encoding for categorical variables
- TF-IDF vectorization of review text
- Created a dual-pipeline: one for `reviewText`, one for `summary`

### ğŸ“ˆ Modeling
- **Model**: Logistic Regression
  - Parameters: `maxIter=300`, `regParam=0.01`, `elasticNetParam=0.0`
- **Split**: 80% training, 20% testing

---

## ğŸ“Š Results

| Metric        | Value   |
|---------------|---------|
| AUC           | 0.888   |
| Precision     | 0.81    |
| Recall        | 0.35    |
| F1 Score      | 0.49    |

- **Top Feature**: Review Length (strongest positive coefficient)
- **TF-IDF terms**: Most important = "try", "style", "intend"; Least = "scary", "advantage"
- Verified reviews were surprisingly **less** helpful

---

## ğŸ’¡ Business Insights

- Longer, more recent reviews tend to be marked as more helpful
- Overused or generic words negatively affect helpfulness
- Helpful reviews often include specific intent or advice
- Overall product rating and verification status are weak predictors of helpfulness

---

## ğŸ’° Cost Breakdown

| Component             | Value                |
|----------------------|----------------------|
| Duration             | 4 weeks              |
| Analysts             | 6                    |
| Analyst Hours/Day    | 3                    |
| Cost per Hour        | $50                  |
| **Total Human Cost** | **$25,200**          |
| Compute Cost         | $436.80 (Databricks) |
| **Total Cost**       | **$25,636.80**       |

---

## ğŸ“ Repository Structure
```
â”œâ”€â”€ 00_TeamAdelaide_Presentation.pdf # Final project presentation.
â”œâ”€â”€ TF-IDF.ipynb # Main model. Simplest but with best results.
â”œâ”€â”€ TF-IDF_plus_Word2Vec.ipynb  # Adds model insights using regression coefficients of grouped features to main model
â”œâ”€â”€ Embeddings_Plus_POStagging.ipynb  # Adds Word2Vec and additional NLP techniques mentioned above
â”œâ”€â”€ Embeddings_Plus_POStagging_v2.ipynb  # Adds Word2Vec, additional NLP techniques individually (Not in a pipeline)
â”œâ”€â”€ README.md # You're here!
```

---
## ğŸ“¬ Contact

**Ishaan Sinha**  
ğŸ“« [ishaan.sinha1997@gmail.com](mailto:ishaan.sinha1997@gmail.com)  
ğŸ”— [LinkedIn](https://ca.linkedin.com/in/ishaan-sinha-56a968167)

---
